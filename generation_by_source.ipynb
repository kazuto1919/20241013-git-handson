{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuto1919/20241013-git-handson/blob/main/generation_by_source.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqJlr-_fQVCb",
        "outputId": "bd511b72-954b-4dbe-febe-06ab034a0d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import holidays\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from openpyxl import Workbook\n",
        "from openpyxl import load_workbook\n",
        "from glob import glob\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "timestamp = now.strftime(\"%Y%m%d\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# インプットディレクトとアウトプットディレクトリの作成\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/electrica/data_analysis/1_tso')\n",
        "current_dir = os.getcwd()\n",
        "input_dir =os.path.join(current_dir, 'input')\n",
        "output_dir = os.path.join(current_dir, 'output')\n",
        "\n"
      ],
      "metadata": {
        "id": "TX2lw1YeyePn"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gFsrf__zx6bL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt_uqixnAXQ-"
      },
      "source": [
        "#2024年以前のデータ処理　基本的に一度だけ回す"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 四国を除く、各エリアのcsvファイルの取得（四国はexcelファイルのため）\n",
        "\n",
        "areas = ['hepco', 'tohoku', 'tepco', 'chubu', 'hokuriku', 'kepco', 'chugoku','kyushu']\n",
        "area_files = {}\n",
        "for area in areas:\n",
        "    file_pattern = os.path.join(input_dir, area + '*pre.csv')\n",
        "    area_files[area] = glob(file_pattern)\n",
        "\n",
        "# 四国エリアのexcelファイルの取得\n",
        "\n",
        "shikoku_pattern = os.path.join(input_dir, 'shikoku*.xlsx')\n",
        "area_files['shikoku'] = glob(shikoku_pattern)"
      ],
      "metadata": {
        "id": "yFrCJHEdMiB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "qYSY1JNkDu3K"
      },
      "outputs": [],
      "source": [
        "#コラムが統一される前の各エリアのコラム名の設定\n",
        "\n",
        "hokkaido_columns_before2024 = ('date','time','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector', 'total_generation')\n",
        "tohoku_columns_before2024 = ('datetime','total_demand', 'hydro', 'fuel', 'nuclear', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'geothermal', 'biomass', 'pumped_storage', 'interconnector')\n",
        "tokyo_columns_before2024 = ('date','time','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector', 'total_generation')\n",
        "chubu_columns_before2024 =  ('date','time','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector')\n",
        "hokuriku_columns_before2024 = ('date','time','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector')\n",
        "kepco_columns_before2024 = ('datetime','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector')\n",
        "chugoku_columns_before2024 = ('date','time','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector')\n",
        "shikoku_columns_before2024 = ('date','time','total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector', 'total_generation')\n",
        "kyushu_columns_before2024 = ('datetime', 'total_demand', 'nuclear', 'fuel', 'hydro', 'geothermal', 'biomass', 'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'interconnector')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "BXjobNoYHnGf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "以下各エリアの2024年以前のコラム名が統一される前のデータの集計\n",
        "エリアによって、日付のフォーマットや空白行数が異なるため、繰り返し動作にはしていない\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 北海道エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['hepco']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=3)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=3)\n",
        "  data_frames.append(df)\n",
        "  df.columns = hokkaido_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = merged_df['date'].ffill()\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "merged_df['time'] = merged_df['time'].str.replace('時', '')\n",
        "\n",
        "output_files = os.path.join(output_dir, f'hokkaido_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "# 東北エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['tohoku']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS')\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8')\n",
        "  data_frames.append(df)\n",
        "  df.columns = tohoku_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['datetime'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "merged_df['time'] = merged_df['date'].dt.time\n",
        "\n",
        "output_files = os.path.join(output_dir, f'tohoku_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "#東京エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['tepco']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=2)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=2)\n",
        "  data_frames.append(df)\n",
        "  df.columns = tokyo_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "\n",
        "output_files = os.path.join(output_dir, f'tokyo_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "# 中部エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['chubu']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=4)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=4)\n",
        "  data_frames.append(df)\n",
        "  df.columns = chubu_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "\n",
        "output_files = os.path.join(output_dir, f'chubu_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "#北陸エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['hokuriku']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=5)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=5)\n",
        "  data_frames.append(df)\n",
        "  df.columns = hokuriku_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'], errors='coerce')\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "\n",
        "output_files = os.path.join(output_dir, f'hokuriku_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "#関西エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['kepco']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=1)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=1)\n",
        "  data_frames.append(df)\n",
        "  df.columns = kepco_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['datetime'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "merged_df['time'] = merged_df['date'].dt.time\n",
        "\n",
        "output_files = os.path.join(output_dir, f'kansai_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "#中国エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['chugoku']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=2)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=2)\n",
        "  data_frames.append(df)\n",
        "  df.columns = chugoku_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "\n",
        "output_files = os.path.join(output_dir, f'chugoku_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "#四国エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['shikoku']:\n",
        "    df = pd.read_excel(file)\n",
        "    data_frames.append(df)\n",
        "    df.columns = shikoku_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "\n",
        "output_files = os.path.join(output_dir, f'shikoku_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')\n",
        "\n",
        "#九州エリア\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for file in area_files['kyushu']:\n",
        "  try:\n",
        "    df = pd.read_csv(file, encoding='shift-JIS', skiprows=1)\n",
        "  except UnicodeDecodeError:\n",
        "    df = pd.read_csv(file, encoding='utf-8', skiprows=1)\n",
        "  data_frames.append(df)\n",
        "  df.columns = kyushu_columns_before2024\n",
        "\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "merged_df['date'] = pd.to_datetime(merged_df['datetime'])\n",
        "merged_df['year'] = merged_df['date'].dt.year\n",
        "merged_df['month'] = merged_df['date'].dt.month\n",
        "merged_df['day'] = merged_df['date'].dt.day\n",
        "merged_df['time'] = merged_df['date'].dt.time\n",
        "\n",
        "output_files = os.path.join(output_dir, f'kyushu_old_total_{timestamp}.csv')\n",
        "merged_df.to_csv(output_files, index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsaN7UibDgbz"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# これはコードとして書式設定されます\n",
        "```\n",
        "\n",
        "#2024年以降のデータ処理　ファイルが更新されるごとに回す"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzacUDhOAWSx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "tlR9yK7dQiNc"
      },
      "outputs": [],
      "source": [
        "#各エリアのcsvファイルの取得\n",
        "\n",
        "hepcofiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_01.csv')\n",
        "tohokufiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_02.csv')\n",
        "tepcofiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_03.csv')\n",
        "chubufiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_04.csv')\n",
        "hokurikufiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_05.csv')\n",
        "kepcofiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_06.csv')\n",
        "chugokufiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_07.csv')\n",
        "shikokufiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_08.csv')\n",
        "kyushufiles = glob('/content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_' + '*_09.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "uxeI8AsfT0HK"
      },
      "outputs": [],
      "source": [
        "# コラム名の設定　各エリア共通\n",
        "\n",
        "columns = ('date','time','total_demand', 'nuclear', 'lng', 'coal', 'oil', 'other_fuel',  'hydro', 'geothermal', 'biomass',\n",
        "                  'pv', 'pv_curtailment', 'wind', 'wind_curtailment', 'pumped_storage', 'bess', 'interconnector', 'other', 'total_generation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "DDqc0o9WV9Ue"
      },
      "outputs": [],
      "source": [
        "# データの集計とアウトプットファイル保存の関数定義\n",
        "\n",
        "def process_and_save(files, area_name):\n",
        "  data_frames = []\n",
        "\n",
        "  for file in files:\n",
        "      try:\n",
        "          df = pd.read_csv(file, encoding='shift-JIS', skiprows=1)\n",
        "      except UnicodeDecodeError:\n",
        "          df = pd.read_csv(file, encoding='utf-8', skiprows=1)\n",
        "      data_frames.append(df)\n",
        "      df.columns = columns\n",
        "\n",
        "  merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "  merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
        "  merged_df['year'] = merged_df['date'].dt.year\n",
        "  merged_df['month'] = merged_df['date'].dt.month\n",
        "  merged_df['day'] = merged_df['date'].dt.day\n",
        "\n",
        "  output_files = os.path.join(output_dir, f'{area_name}_total_{timestamp}.csv')\n",
        "  merged_df.to_csv(output_files, index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLOYS_RLxtlg"
      },
      "outputs": [],
      "source": [
        "# 中国エリア以外のデータ集計操作、中国エリアはいくつかのファイルでコラム数が違うため別処理\n",
        "\n",
        "process_and_save(hepcofiles, 'hepco')\n",
        "process_and_save(tohokufiles, 'tohoku')\n",
        "process_and_save(tepcofiles, 'tepco')\n",
        "process_and_save(chubufiles, 'chubu')\n",
        "process_and_save(hokurikufiles, 'hokuriku')\n",
        "process_and_save(kepcofiles, 'kansai')\n",
        "process_and_save(shikokufiles, 'shikoku')\n",
        "process_and_save(kyushufiles, 'kyushu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "Xbc6T5n3xxXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210e52b6-7ff8-4d5b-b74d-522f4e6a080a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202404_07.csv, Number of columns: 20\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202405_07.csv, Number of columns: 20\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202406_07.csv, Number of columns: 20\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202407_07.csv, Number of columns: 20\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202408_07.csv, Number of columns: 20\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202409_07.csv, Number of columns: 20\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202410_07.csv, Number of columns: 22\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202411_07.csv, Number of columns: 22\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202412_07.csv, Number of columns: 22\n",
            "File: /content/drive/MyDrive/electrica/data_analysis/1_tso/input/eria_jukyu_202501_07.csv, Number of columns: 22\n"
          ]
        }
      ],
      "source": [
        "# 中国エリアインプットファイル内のコラム数　確認\n",
        "\n",
        "for file in chugokufiles:\n",
        "    try:\n",
        "        df = pd.read_csv(file, encoding='shift-JIS', skiprows=1)\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(file, encoding='utf-8', skiprows=1)\n",
        "    num_cols = len(df.columns)\n",
        "    print(f\"File: {file}, Number of columns: {num_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sltSqMNON8rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dMePhU8cfIju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2024年以前以後のデータの統合"
      ],
      "metadata": {
        "id": "UFvjjCwaDTZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#　2024年以前の集計後ファイルの読み込み\n",
        "\n",
        "hokkaido_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/hokkaido_old_total_20250217.csv')\n",
        "tohoku_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/tohoku_old_total_20250217.csv')\n",
        "tokyo_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/tokyo_old_total_20250217.csv')\n",
        "chubu_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/chubu_old_total_20250217.csv')\n",
        "hokuriku_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/hokuriku_old_total_20250217.csv')\n",
        "kansai_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/kansai_old_total_20250217.csv')\n",
        "chugoku_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/chugoku_old_total_20250217.csv')\n",
        "shikoku_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/shikoku_old_total_20250217.csv')\n",
        "kyushu_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/kyushu_old_total_20250217.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOlFYhTBDOSP",
        "outputId": "3fcedc73-1eb7-490a-f704-b029f90b954b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-148-1a01a214c0e2>:3: DtypeWarning: Columns (2,4,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  tokyo_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/tokyo_old_total_20250217.csv')\n",
            "<ipython-input-148-1a01a214c0e2>:5: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  hokuriku_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/hokuriku_old_total_20250217.csv')\n",
            "<ipython-input-148-1a01a214c0e2>:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  kansai_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/kansai_old_total_20250217.csv')\n",
            "<ipython-input-148-1a01a214c0e2>:7: DtypeWarning: Columns (0,1,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  chugoku_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/chugoku_old_total_20250217.csv')\n",
            "<ipython-input-148-1a01a214c0e2>:9: DtypeWarning: Columns (1,2,3,8,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  kyushu_old_total = pd.read_csv('/content/drive/MyDrive/electrica/data_analysis/1_tso/output/kyushu_old_total_20250217.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 単位1万kWのエリアを1MWに合わせる\n",
        "\n",
        "# 北海道エリア\n",
        "\n",
        "hokkaido_old_total_adj = hokkaido_old_total.loc[:, 'total_demand':'total_generation'] * 10\n",
        "hokkaido_old_total_adj['date'] = hokkaido_old_total['date']\n",
        "hokkaido_old_total_adj['time'] = hokkaido_old_total['time']\n",
        "hokkaido_old_total_adj['year'] = hokkaido_old_total['year']\n",
        "hokkaido_old_total_adj['month'] = hokkaido_old_total['month']\n",
        "hokkaido_old_total_adj['day'] = hokkaido_old_total['day']\n",
        "\n",
        "#東京エリア\n",
        "\n",
        "tokyo_old_total_adj = tokyo_old_total.loc[:, 'total_demand':'total_generation'] * 10\n",
        "tokyo_old_total_adj['date'] = tokyo_old_total['date']\n",
        "tokyo_old_total_adj['time'] = tokyo_old_total['time']\n",
        "tokyo_old_total_adj['year'] = tokyo_old_total['year']\n",
        "tokyo_old_total_adj['month'] = tokyo_old_total['month']\n",
        "tokyo_old_total_adj['day'] = tokyo_old_total['day']\n",
        "\n",
        "#四国エリア\n",
        "\n",
        "shikoku_old_total_adj = shikoku_old_total.loc[:, 'total_demand':'total_generation'] * 10\n",
        "shikoku_old_total_adj['date'] = shikoku_old_total['date']\n",
        "shikoku_old_total_adj['time'] = shikoku_old_total['time']\n",
        "shikoku_old_total_adj['year'] = shikoku_old_total['year']\n",
        "shikoku_old_total_adj['month'] = shikoku_old_total['month']\n",
        "shikoku_old_total_adj['day'] = shikoku_old_total['day']"
      ],
      "metadata": {
        "id": "NAf-KtyWEEve"
      },
      "execution_count": 151,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPs0n+yS3WwXGRstWbEIILa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}